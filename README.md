# Distributed MapReduce in Go

This repository contains my implementation of a distributed MapReduce framework in Go, based on MITâ€™s 6.5840 lab assignment. It demonstrates core distributed-systems concepts, robust engineering practices, and production-grade coding skills.

## ğŸ“¦ Project Overview

I built two programs:

- **Coordinator** (master):  
  - Manages the global state of Map and Reduce tasks in memory  
  - Exposes two RPC endpoints:  
    1. `RequestTask` â€“ â€œGive me workâ€  
    2. `ReportTask` â€“ â€œI finished this taskâ€  
  - Tracks task lifecycles (Idle â†’ InProgress â†’ Completed), enforces a 10 s timeout for fault tolerance, and transitions cleanly between Map and Reduce phases.

- **Worker**:  
  - Loops: ask for work â†’ execute â†’ report â†’ repeat  
  - Implements `doMapTask` and `doReduceTask`:  
    - **Map**: reads an input split, applies `mapf`, partitions output via `ihash` into `mr-<mapID>-<reduceID>` files  
    - **Reduce**: reads all `mr-*-<reduceID>` files, sorts & groups by key, applies `reducef`, and writes final `mr-out-<reduceID>` atomically  
  - Handles â€œno workâ€ (backs off with sleep) and â€œexitâ€ signals gracefully.

## ğŸš€ Key Engineering Highlights

- **Concurrency & Synchronization**  
  - Coordinated via `sync.Mutex` to protect shared task state  
  - Per-RPC locking ensures correctness under high concurrency

- **Fault Tolerance & Retry**  
  - Unfinished tasks automatically re-queued after 10 s  
  - Graceful recovery from worker crashes (tested with random â€œcrashâ€ plugin)

- **Atomic File I/O**  
  - Uses Goâ€™s `os.CreateTemp` + `os.Rename` to guarantee atomic writes  
  - Clean-up of stale or partial files on failures

- **Clean RPC Design**  
  - Minimal, well-typed Go `net/rpc` interfaces  
  - UNIX-domain sockets simplify local testing while mirroring real-world RPC

- **Testable & Race-Free**  
  - Comprehensive end-to-end test script (`test-mr.sh`) validates correctness, parallelism, and crash recovery  
  - Verified with Goâ€™s race detector (`go run -race`)

## ğŸ“ Architecture Diagram

```mermaid
flowchart TB
  subgraph Coordinator
    C0[Initialize mapTasks & reduceTasks]
    C1[RPC: RequestTask] --> Dispatch(Map/Reduce/NoTask/Exit)
    C2[RPC: ReportTask]  --> Update status & check phase
  end

  subgraph Worker
    W0[Loop]
    W0 --> |RequestTask| C1
    C1 --> |MapTask| W1[doMapTask] --> |ReportTask| C2
    C1 --> |ReduceTask| W2[doReduceTask] --> |ReportTask| C2
    C1 --> |NoTask| W3[Sleep 1s]
    C1 --> |ExitTask| W4[Exit]
  end
